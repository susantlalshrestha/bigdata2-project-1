---
title: "Project 1 - Exploring Car Crash Dataset using R"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```{r}
#Load data into R studio
df <- read.csv("./monroe county car crach 2003-2015.csv")
df
```
```{r}
#Quick facts about the dataset
summary(df)
dim(df)
colSums(is.na(df))
```
```{r}
#Drop duplicates and NA values
clean_df <- df[complete.cases(df) & !duplicated(df), ]
colSums(is.na(clean_df))
```

```{r}
#Convert the hour into readable format
library(dplyr)
convert_float_to_time <- function(time_float) {
  time_str <- gsub("\\.0", "", as.character(time_float))
  time_str <- sprintf("%04d", as.integer(time_str))
  
  hours <- substr(time_str, 1, nchar(time_str) - 2)
  minutes <- substr(time_str, nchar(time_str) - 1, nchar(time_str))
  
  return(paste(hours, minutes, sep = ":"))
  
}
```
```{r}
clean_df <- clean_df %>% 
  mutate(Hour = convert_float_to_time(Hour))
head(clean_df$Hour)
```
```{r}
head(clean_df)
```
```{r}
# Add ID to each row
clean_dfID <- clean_df %>% mutate(ID = row_number())
head(clean_dfID)
```

NOTE: USE clean_dfID for findings


```{r}
#Number of accidents by years, months, days and hours

library(dplyr)
library(ggplot2)

group_list <- c("Year", "Month", "Day", "Hour")

for (i in group_list) {
  grouped <- df %>%
    group_by_at(vars({{i}})) %>%
    summarise(count = n()) %>%
    ungroup()
  
  cols <- ifelse(grouped$count < max(grouped$count), "green", "orange")
  
  countOfAccidents <- ggplot(grouped, aes_string(x = i, y = "count", fill = "cols")) +
    geom_bar(stat = "identity") +
    theme_minimal() +
    ggtitle(paste("Number of accidents by", i)) +
    theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
    labs(x = "", y = "Count") +
    scale_fill_identity(name = "Color", labels = c("Less than max", "Max count"))
  
  print(countOfAccidents)
  
}
```

```{r}
#Number and rates of accidents on weekdays and weekends
df_filtered <- df %>%
  filter(`Weekend.` %in% c("Weekend", "Weekday"))

# Group and summarize
grouped_week <- df_filtered %>%
  group_by(`Weekend.`) %>%
  summarise(count = n()) %>%
  ungroup()

print(grouped_week)
```
```{r}
# Define color palette
col_pal <- c("#1f77b4", "#ff7f0e")

# Plotting barplot and pie chart
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Barplot
barplot(grouped_week$count, names.arg = grouped_week$`Weekend.`, 
        col = col_pal[3], main = "Number of accidents on weekdays and weekends",
        xlab = "", ylab = "Count")

# Pie chart
pie(grouped_week$count, labels = grouped_week$`Weekend.`, 
    main = "Percentage of accidents on weekdays and weekends", 
    col = col_pal, init.angle = 45)

# Adding legend
legend("topright", legend = grouped_week$`Weekend.`, fill = col_pal, title = "Weekend", cex = 0.8)

# Reset par settings
par(mfrow = c(1, 1))
```

```{r}
#Cause of accidents

# Group by "Primary Factor", calculate counts, and reset index
grouped_primary_factor <- df %>%
  group_by(`Primary.Factor`) %>%
  summarise(counts = n()) %>%
  ungroup()

# Sort the data frame by counts in descending order and select the top 10 rows
grouped_primary_factor <- grouped_primary_factor %>%
  arrange(desc(counts)) %>%
  head(10)

print(grouped_primary_factor)
```
```{r}
# Plotting the bar chart
ggplot(grouped_primary_factor, aes(x = reorder(`Primary.Factor`, -counts), y = counts)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  theme_minimal() +
  labs(title = "Top 10 Primary Factors",
       x = "Primary Factor",
       y = "Counts") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_flip()
```

```{r}
#Plot a bar chat for Collision Type
collision_counts <- table(clean_dfID$`Collision.Type`)
collision_plot <- ggplot(data = clean_dfID, aes(x = `Collision.Type`)) +
  geom_bar(fill = "skyblue") +
  labs(title = "Total Count of Each Collision Type", x = "Collision Type", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

collision_plot
```



```{r}
# Plot a line graph showing the trend of accidents
date_counts <- clean_dfID %>%
  group_by(Date = as.Date(paste(Year, Month, Day, sep = "-"))) %>%
  summarize(Count = n())

trend_plot <- ggplot(data = date_counts, aes(x = Date, y = Count)) +
  geom_line() +
  labs(title = "Trend of Accidents Over Time", x = "Date", y = "Number of Accidents") +
  theme_minimal()

trend_plot
```

```{r}
#Training the model for insights
library(caret)

# Define the target variable and features
target <- "Injury.Type"
features <- setdiff(names(clean_dfID), c("Injury.Type", "ID"))

# Split the data into training (70%) and testing (30%)
set.seed(123)
trainIndex <- createDataPartition(clean_dfID$Injury.Type, p = .7, 
                                  list = FALSE, 
                                  times = 1)
data_train <- clean_dfID[trainIndex, ]
data_test  <- clean_dfID[-trainIndex, ]

# Create a training control with 5-fold cross-validation
train_control <- trainControl(method = "cv", number = 5)

# Train the model
model <- train(data_train[, features], data_train[, target], 
               method = "rf", 
               trControl = train_control)

# Print the model
print(model)

# Make predictions on the training set
train_predictions <- predict(model, data_train[, features])

# Calculate training accuracy
train_accuracy <- confusionMatrix(train_predictions,as.factor(data_train[, target]))$overall["Accuracy"]
print(paste("Training Accuracy:", train_accuracy))

# Make predictions on the test set
test_predictions <- predict(model, data_test[, features])

# Calculate test accuracy
test_accuracy <- confusionMatrix(test_predictions, as.factor(data_test[, target]))$overall["Accuracy"]
print(paste("Test Accuracy:", test_accuracy))
```

```{r}
library(shiny)
library(dplyr)
library(ggplot2)

# Define UI
ui <- fluidPage(
  titlePanel("Accident Data Analysis"),
  sidebarLayout(
    sidebarPanel(
      selectInput("group", "Group by:", choices = c("Year", "Month", "Day", "Hour"))
    ),
    mainPanel(
      plotOutput("plot")
    )
  )
)

# Define server logic
server <- function(input, output) {
  
  output$plot <- renderPlot({
    group_var <- input$group
    
    grouped <- df %>%
      group_by_at(vars(group_var)) %>%
      summarise(count = n()) %>%
      ungroup()
    
    cols <- ifelse(grouped$count < max(grouped$count), "green", "orange")
    
    ggplot(grouped, aes_string(x = group_var, y = "count", fill = "cols")) +
      geom_bar(stat = "identity") +
      theme_minimal() +
      ggtitle(paste("Number of accidents by", group_var)) +
      theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
      labs(x = "", y = "Count") +
      scale_fill_identity(name = "Color", labels = c("Less than max", "Max count"))
  })
}

# Run the application 
shinyApp(ui = ui, server = server)
```

